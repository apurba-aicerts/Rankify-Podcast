{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e546331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1c8683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c2ed161",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"TTS the following conversation between Leo and Elena:\n",
    "Leo: You know, I spend half my day talking to AI bots. I ask for a plan, they give me a plan. I ask for a recipe, they give me a recipe. But at the end of the day, I'm still the one chopping the onions, you know?\n",
    "\n",
    "Elena: I know exactly what you mean. You're stuck in the gap between the idea and the execution. The AI has the 'mind', but you have to be the 'hands'.\n",
    "\n",
    "Leo: Right! I want an AI that doesn't just tell me how to do something, but actually... does it. And I heard rumors that we might finally be getting there?\n",
    "\n",
    "Elena: We are. That's actually the perfect segue to talk about Manus AI. It’s a new general-purpose agent that dropped early in 2025, developed by a startup called Monica.im.\n",
    "\n",
    "Leo: Monica.im? I think I've seen their browser extensions before. So what makes Manus different from the fifty other models that came out last week?\n",
    "\n",
    "Elena: The core philosophy is different. They describe it as bridging the gap between 'mind' and 'hand'. Most LLMs we use today are pure 'mind'—they think, they plan, they generate text. Manus is designed to execute.\n",
    "\n",
    "Leo: Okay, 'execute' is a strong word. Are we talking about it writing code and running it? Or is it actually browsing the web and clicking buttons?\n",
    "\n",
    "Elena: Both, and more. It's designed for end-to-end task completion. So instead of just drafting an email for you to copy-paste, it could draft it, find the recipient's address, and send it. But it goes much deeper than administrative tasks.\n",
    "\n",
    "Leo: Give me the heavy hitters. Where is this actually being used?\n",
    "\n",
    "Elena: Well, the paper on it highlights some massive industries. Healthcare, finance, manufacturing, and even gaming. In finance, for example, it’s not just summarizing news. It could theoretically analyze real-time market trends, cross-reference them with a portfolio, and generate a tangible risk report without you guiding every step.\n",
    "\n",
    "Leo: That’s a huge shift. It feels like moving from a consultant who gives advice to an employee who does the work.\n",
    "\n",
    "Elena: That is the perfect analogy. It’s a shift toward autonomous agents. The goal is to take a high-level intention—like 'plan my business trip'—and turn it into an actionable outcome, like booked flights and a calendar filled with meetings.\n",
    "\n",
    "Leo: It sounds incredible, but also... a little risky? I mean, if the 'hand' makes a mistake, that's a real-world consequence. It's not just a hallucinated fact I can ignore.\n",
    "\n",
    "Elena: Absolutely. And that is the biggest limitation right now. When you give an AI agency—the ability to act—reliability becomes critical. We are still in the early glimpse phase. It's not perfect.\n",
    "\n",
    "Leo: So, we're not quite at the point where I can let it run my life while I sleep.\n",
    "\n",
    "Elena: Not quite. But Manus AI is signaling a new paradigm. It's moving us away from 'chatting' with AI to collaborating with it. It augurs a future where the friction between wanting something done and having it done basically disappears.\n",
    "\n",
    "Leo: Mind and hand working together. I like the sound of that. Thanks for breaking it down, Elena.\n",
    "\n",
    "Elena: Anytime, Leo.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a9da3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"TTS the following conversation between Maya and John:\n",
    "Maya: You know, for the last few years, we’ve gotten really used to AI that talks. We ask a question, it writes a poem or summarizes a document. It feels like magic.\n",
    "\n",
    "John: It does. But it’s a very specific kind of magic. It’s passive. It’s waiting for you to prompt it, and its output is usually just... text.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d953d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved out_1.wav successfully!\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import wave\n",
    "\n",
    "# Function to save PCM data to a WAV file\n",
    "def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n",
    "    with wave.open(filename, \"wb\") as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(sample_width)\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(pcm)\n",
    "\n",
    "# Initialize client with API key\n",
    "client = genai.Client(api_key=api_key)  # <- Replace with your key\n",
    "\n",
    "# prompt = \"\"\"TTS the following conversation between Joe and Apurba:\n",
    "# Joe: How's it going today Apurba?\n",
    "# Apurba: Not too bad, how about you?\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-preview-tts\",\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_modalities=[\"AUDIO\"],\n",
    "        speech_config=types.SpeechConfig(\n",
    "            multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(\n",
    "                speaker_voice_configs=[\n",
    "                    \n",
    "                    types.SpeakerVoiceConfig(\n",
    "                        speaker='Maya',\n",
    "                        voice_config=types.VoiceConfig(\n",
    "                            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "                                voice_name='achernar',\n",
    "                            )\n",
    "                        )\n",
    "                    ),\n",
    "                    types.SpeakerVoiceConfig(\n",
    "                        speaker='John',\n",
    "                        voice_config=types.VoiceConfig(\n",
    "                            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "                                voice_name='enceladus',\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Extract audio data and save\n",
    "data = response.candidates[0].content.parts[0].inline_data.data\n",
    "wave_file(\"out_4.wav\", data)\n",
    "print(\"Saved out_1.wav successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01f72b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ApurbaManna\\AppData\\Local\\Temp\\ipykernel_20120\\833625666.py:2: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  response_data = response.json()\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "response_data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0603c69",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresponse_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43musage_metadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "response_data[\"usage_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225c7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata.prompt_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "731c2778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=81,\n",
       "  candidates_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.AUDIO: 'AUDIO'>,\n",
       "      token_count=81\n",
       "    ),\n",
       "  ],\n",
       "  prompt_token_count=38,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=38\n",
       "    ),\n",
       "  ],\n",
       "  total_token_count=119\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93624498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            inline_data=Blob(\n",
       "              data=<... Max depth ...>,\n",
       "              mime_type=<... Max depth ...>\n",
       "            )\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "      index=0\n",
       "    ),\n",
       "  ],\n",
       "  model_version='gemini-2.5-flash-preview-tts',\n",
       "  response_id='LvlgabedGrqvg8UPp7ODsA4',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=11>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=78,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.AUDIO: 'AUDIO'>,\n",
       "        token_count=78\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=32,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=32\n",
       "      ),\n",
       "    ],\n",
       "    total_token_count=110\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554badbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "podcast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
